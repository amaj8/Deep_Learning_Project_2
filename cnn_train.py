# -*- coding: utf-8 -*-
"""Copy of DL assignment 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g3CgRybpCa_B74ZDJxwOybhhqJ5GWEpE
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import torchvision
import torchvision.transforms as transforms
import time

#Load the FashionMNIST training dataset
train_set = torchvision.datasets.FashionMNIST(
    root = './data/FashionMNIST',
    train = True,
    download = True,
    transform = transforms.Compose([transforms.ToTensor()])
)

#Load the FashionMNIST test dataset
test_set = torchvision.datasets.FashionMNIST(
    root = './data/FashionMNIST',
    train = False,
    download = True,
    transform = transforms.Compose([transforms.ToTensor()])
)

class Network(nn.Module):
  def __init__(self):
    super().__init__()

    #Layers definition
    self.conv1 = nn.Conv2d(in_channels=1, out_channels = 6, kernel_size = 5, padding=(1,1))
    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5,padding=(1,1))
    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)
    self.fc2 = nn.Linear(in_features=120, out_features=60)
    self.out = nn.Linear(in_features=60, out_features=10)

  def forward(self,x):
    #1st convolutional layer
    x = self.conv1(x)
    x = F.relu(x)
    x = F.max_pool2d(x,kernel_size=2,stride=2)

    #2nd convolutional layer
    x = self.conv2(x)
    x = F.relu(x)
    x = F.max_pool2d(x,kernel_size=2, stride=3)

    #1st fully connected layer
    x = x.reshape(-1,12*4*4)
    #x = x.view(x.size(0), -1)
    x = self.fc1(x)
    x = F.relu(x)

    #2nd fully connected layer
    x = self.fc2(x)
    x = F.relu(x)

    #output
    x = self.out(x)

    return x

net = Network()
# print(net)

#Hyperparameters
LEARNING_RATE = 0.01
#optimizer = torch.optim.SGD(net.parameters(), lr = LEARNING_RATE, momentum=0.09)
optimizer = torch.optim.SGD(net.parameters(), lr = LEARNING_RATE, momentum=0.09, weight_decay=1e-6)   
#optimizer = torch.optim.Adam(net.parameters(), lr = LEARNING_RATE)
loss_fn = nn.CrossEntropyLoss()

EPOCHS =100
BATCH_SIZE = 100
loader = torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE, shuffle=True)

def evaluate_accuracy(net, loader):
  net.eval()
  correct,total = 0,0
  for batch in loader:
    images, labels = batch
    net_test_output = net(images)
    _,predicted = torch.max(net_test_output.data,1)
    correct += (predicted == labels).sum()
    total += labels.size(0)

  accuracy = 100. * correct/total
  return accuracy

if __name__ == "__main__":

  total_loss_list = []
  mean_loss_list = []
  training_accuracy_list = []
  test_accuracy_list = []

  start_time = time.time()
  for epoch in range(EPOCHS):
    total_loss = 0  
    total_correct = 0
    total_labels = 0
    for batch in loader:    
      images = batch[0]
      labels = batch[1]
      predictions = net(images)

      _,predicted = torch.max(predictions,1)
      total_correct += (predicted == labels).sum()
      total_labels += labels.size(0)

      loss = loss_fn(predictions,labels)

      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      total_loss += loss.item() 

    if epoch%2 == 0:
      print('Epoch#',epoch+1,'\t','Loss:',total_loss)   
      
    
    training_accuracy = 100. * total_correct/total_labels
    training_accuracy_list.append(training_accuracy)

    test_accuracy = evaluate_accuracy(net,test_loader)
    test_accuracy_list.append(test_accuracy)

    mean_loss= total_loss/600
    total_loss_list.append(total_loss)
    mean_loss_list.append(mean_loss)

      #Training accuracy
      # total, correct = 0,0
      # net.eval()
      # for batch in loader:
      #   images, labels = batch
      #   net_train_output = net(images)
      #   _,predicted = torch.max(net_train_output.data,1)
      #   correct += (predicted == labels).sum()
      #   total += labels.size(0)

      # training_accuracy = 100. * correct/total
      # training_accuracy_list.append(training_accuracy)

      # #Test accuracy
      # test_total, test_correct = 0,0
      # net.eval()
      # for batch in test_loader:
      #   images, labels = batch
      #   net_test_output = net(images)
      #   _,predicted = torch.max(net_test_output.data,1)
      #   test_correct += (predicted == labels).sum()
      #   test_total += labels.size(0)

      # test_accuracy = 100. * test_correct/test_total
      # test_accuracy_list.append(test_accuracy)

  end_time = time.time() - start_time
  print('Training time for ' + str(EPOCHS) + ' epochs: ' + str(end_time))

  import matplotlib.pyplot as plt
  epoch_list = [i+1 for i in range(EPOCHS)]
  plt.plot(epoch_list,total_loss_list)
  plt.xlabel('Epochs')
  plt.ylabel('Total Loss')
  plt.show()

  plt.plot(epoch_list,mean_loss_list)
  plt.xlabel('Epochs')
  plt.ylabel('Mean Loss')
  plt.show()

  plt.plot(epoch_list,training_accuracy_list)
  plt.xlabel('Epochs')
  plt.ylabel('Training accuracy')
  plt.show()

  plt.plot(epoch_list,test_accuracy_list)
  plt.xlabel('Epochs')
  plt.ylabel('Test accuracy')
  plt.show()

  #Hyperparameters
  LEARNING_RATE = 0.01
  #optimizer = torch.optim.SGD(net.parameters(), lr = LEARNING_RATE, momentum=0.09)
  optimizer = torch.optim.Adam(net.parameters(), lr = LEARNING_RATE, weight_decay=1e-6)   
  #optimizer = torch.optim.Adam(net.parameters(), lr = LEARNING_RATE)
  loss_fn = nn.CrossEntropyLoss()

  Adam_total_loss_list = []
  Adam_mean_loss_list = []
  Adam_training_accuracy_list = []
  Adam_test_accuracy_list = []

  start_time = time.time()
  for epoch in range(EPOCHS):
    total_loss = 0  
    total_correct = 0
    total_labels = 0
    for batch in loader:    
      images = batch[0]
      labels = batch[1]
      predictions = net(images)

      _,predicted = torch.max(predictions,1)
      total_correct += (predicted == labels).sum()
      total_labels += labels.size(0)

      loss = loss_fn(predictions,labels)

      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      total_loss += loss.item() 

    if epoch%2 == 0:
      print('Epoch#',epoch+1,'\t','Loss:',total_loss)   
      
    
    training_accuracy = 100. * total_correct/total_labels
    Adam_training_accuracy_list.append(training_accuracy)

    test_accuracy = evaluate_accuracy(net,test_loader)
    Adam_test_accuracy_list.append(test_accuracy)

    mean_loss= total_loss/600
    Adam_total_loss_list.append(total_loss)
    Adam_mean_loss_list.append(mean_loss)

     
  end_time = time.time() - start_time
  print('Training time for ' + str(EPOCHS) + ' epochs: ' + str(end_time))

  # from google.colab import drive
  # drive.mount('/content/gdrive',force_remount=True)
  # network_save_name = 'cnn_with_L2regulariser_3.pth'
  # PATH = F"/content/gdrive/My Drive/Colab Notebooks/{network_save_name}" 
  # # torch.save(net.state_dict(), PATH)
  # torch.save(net, PATH)

  # from google.colab import drive
  # drive.mount('/content/gdrive',force_remount=True)
  # network_save_name = 'cnn_with_L2regulariser_3.pth'
  # PATH = F"/content/gdrive/My Drive/{network_save_name}" 
  # # torch.save(net.state_dict(), PATH)
  # net = torch.load(PATH)

  # test_set = torchvision.datasets.FashionMNIST(
  #     root = './data/FashionMNIST',
  #     train = False,
  #     download = True,
  #     transform = transforms.Compose([transforms.ToTensor()])
  # )

  # class Network(nn.Module):
  #   def __init__(self):
  #     super().__init__()

  #     #Layers definition
  #     self.conv1 = nn.Conv2d(in_channels=1, out_channels = 6, kernel_size = 5)
  #     self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)
  #     self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)
  #     self.fc2 = nn.Linear(in_features=120, out_features=60)
  #     self.out = nn.Linear(in_features=60, out_features=10)

  #   def forward(self,x):
  #     #1st convolutional layer
  #     x = self.conv1(x)
  #     x = F.relu(x)
  #     x = F.max_pool2d(x,kernel_size=2,stride=2)

  #     #2nd convolutional layer
  #     x = self.conv2(x)
  #     x = F.relu(x)
  #     x = F.max_pool2d(x,kernel_size=2, stride=2)

  #     #1st fully connected layer
  #     x = x.reshape(-1,12*4*4)
  #     #x = x.view(x.size(0), -1)
  #     x = self.fc1(x)
  #     x = F.relu(x)

  #     #2nd fully connected layer
  #     x = self.fc2(x)
  #     x = F.relu(x)

  #     #output
  #     x = self.out(x)

  #     return x

  # network_save_name = 'cnn_with_L2regulariser_data_augmented.pth'
  # PATH = F"/content/gdrive/My Drive/{network_save_name}"
  # net = torch.load(PATH)

  total, correct = 0,0
  net.eval()
  for batch in loader:
    images, labels = batch
    net_train_output = net(images)
    _,predicted = torch.max(net_train_output.data,1)
    correct += (predicted == labels).sum()
    total += labels.size(0)

  training_accuracy = 100. * correct/total
  #print(total)
  print(training_accuracy)

  test_loader = torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE, shuffle=True)
  test_total, test_correct = 0,0
  net.eval()
  for batch in test_loader:
    images, labels = batch
    net_test_output = net(images)
    _,predicted = torch.max(net_test_output.data,1)
    test_correct += (predicted == labels).sum()
    test_total += labels.size(0)

  test_accuracy = 100. * test_correct/test_total
  #print(test_total)
  print(test_accuracy)