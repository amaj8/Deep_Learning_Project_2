# -*- coding: utf-8 -*-
"""DL assignment 2 NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m-u7alWTL2fQQw0fPlYO9fnlRMzojOo2
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import torchvision
import torchvision.transforms as transforms
import time

#Load the FashionMNIST training dataset
train_set = torchvision.datasets.FashionMNIST(
    root = './data/FashionMNIST',
    train = True,
    download = True,
    transform = transforms.Compose([transforms.ToTensor()])
)

#Load the FashionMNIST test dataset
test_set = torchvision.datasets.FashionMNIST(
    root = './data/FashionMNIST',
    train = False,
    download = True,
    transform = transforms.Compose([transforms.ToTensor()])
)

class MLP(nn.Module):
  def __init__(self):
    super().__init__()
    self.hidden1 = nn.Linear(28*28,150)
    #self.hidden2 = nn.Linear(150,75)
    self.output = nn.Linear(150,10)
    
  def forward(self,x):
    x = x.reshape(-1,28*28)
    x = F.relu(self.hidden1(x))
    # x  = self.hidden2(x)
    # x = F.relu(x)
    x = self.output(x)
    return x

net = MLP()
# print(net)

#Hyperparameters
LEARNING_RATE = 0.01
optimizer = torch.optim.SGD(net.parameters(), lr = LEARNING_RATE, momentum=0.09, weight_decay=1e-5)   
#optimizer = torch.optim.Adam(net.parameters(), lr = LEARNING_RATE)
loss_fn = nn.CrossEntropyLoss()

EPOCHS =100
BATCH_SIZE = 100
loader = torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE, shuffle=True)

def evaluate_accuracy(net, loader):
  net.eval()
  correct,total = 0,0
  for batch in loader:
    images, labels = batch
    net_test_output = net(images)
    _,predicted = torch.max(net_test_output.data,1)
    correct += (predicted == labels).sum()
    total += labels.size(0)

  accuracy = 100. * correct/total
  return accuracy

if __name__ == "__main__":

  total_loss_list = []
  mean_loss_list = []
  training_accuracy_list = []
  test_accuracy_list = []

  start_time = time.time()
  for epoch in range(EPOCHS):
    total_loss = 0  
    total_correct = 0
    total_labels = 0
    for batch in loader:    
      images = batch[0]
      labels = batch[1]
      predictions = net(images)

      _,predicted = torch.max(predictions,1)
      total_correct += (predicted == labels).sum()
      total_labels += labels.size(0)

      loss = loss_fn(predictions,labels)

      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      total_loss += loss.item() 

    if epoch%2 == 0:
      print('Epoch#',epoch+1,'\t','Loss:',total_loss)   
      
    
    training_accuracy = 100. * total_correct/total_labels
    training_accuracy_list.append(training_accuracy)

    test_accuracy = evaluate_accuracy(net,test_loader)
    test_accuracy_list.append(test_accuracy)

    mean_loss= total_loss/600
    total_loss_list.append(total_loss)
    mean_loss_list.append(mean_loss)

  end_time = time.time() - start_time
  print('Training time for ' + str(EPOCHS) + ' epochs: ' + str(end_time))

  import matplotlib.pyplot as plt
  epoch_list = [i+1 for i in range(EPOCHS)]
  plt.plot(epoch_list,total_loss_list)
  plt.xlabel('Epochs')
  plt.ylabel('Total Loss')
  plt.show()

  plt.plot(epoch_list,mean_loss_list)
  plt.xlabel('Epochs')
  plt.ylabel('Mean Loss')
  plt.show()

  plt.plot(epoch_list,training_accuracy_list)
  plt.xlabel('Epochs')
  plt.ylabel('Training accuracy')
  plt.show()

  plt.plot(epoch_list,test_accuracy_list)
  plt.xlabel('Epochs')
  plt.ylabel('Test accuracy')
  plt.show()

  # from google.colab import drive
  # drive.mount('/content/gdrive',force_remount=True)
  # network_save_name = 'nn3.pth'
  # PATH = F"/content/gdrive/My Drive/{network_save_name}" 
  # # torch.save(net.state_dict(), PATH)
  # torch.save(net, PATH)

  # from google.colab import drive
  # drive.mount('/content/gdrive',force_remount=True)
  # network_save_name = 'nn3.pth'
  # PATH = F"/content/gdrive/My Drive/Colab Notebooks/{network_save_name}" 
  # # torch.save(net.state_dict(), PATH)
  # torch.save(net, PATH)

  # from google.colab import drive
  # drive.mount('/content/gdrive',force_remount=True)
  # network_save_name = 'nn3.pth'
  # PATH = F"/content/gdrive/My Drive/Colab Notebooks/{network_save_name}"
  # net = torch.load(PATH)

  # from google.colab import drive
  # drive.mount('/content/gdrive',force_remount=True)
  # network_save_name = 'nn3_data_augmentation.pth'
  # PATH = F"/content/gdrive/My Drive/{network_save_name}"
  # net = torch.load(PATH)

  total, correct = 0,0
  net.eval()
  for batch in loader:
    images, labels = batch
    net_train_output = net(images)
    _,predicted = torch.max(net_train_output.data,1)
    correct += (predicted == labels).sum()
    total += labels.size(0)

  training_accuracy = 100. * correct/total
  #print(total)
  print(training_accuracy)

  test_loader = torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE, shuffle=True)
  test_total, test_correct = 0,0
  net.eval()
  for batch in test_loader:
    images, labels = batch
    net_test_output = net(images)
    _,predicted = torch.max(net_test_output.data,1)
    test_correct += (predicted == labels).sum()
    test_total += labels.size(0)

  test_accuracy = 100. * test_correct/test_total
  #print(test_total)
  print(test_accuracy)